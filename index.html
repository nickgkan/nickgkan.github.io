
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
<title>Nikolaos Gkanatsios</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-149916135-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


</head>

<body>
  <div class="container">
    <table width="900" border="0" align="center" cellpadding="20">
      <table width="90%" align="center" border="0" cellpadding="10">
        <tr>
          <td width="70%" valign="top">
            <p align="center">&nbsp;</p>

            <p align="center"><font size="6px">Nikolaos Gkanatsios</font><br>
            ngkanats@andrew.cmu.edu</p>

            <p>I am a PhD student at the <a href="https://www.ri.cmu.edu/">Robotics Institute</a> of Carnegie Mellon University, advised by Prof. <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a>. Previously, I received my M.Sc./B.Sc. Diploma in Electrical and Computer Engineering from <a href="http://www.ece.ntua.gr/">National Technical University of Athens</a> in Greece, where I also spent 2 more years working with Prof. <a href="http://cvsp.cs.ntua.gr/maragos/">Petros Maragos</a>.</p>

            <p>Before joining CMU, I worked as an ML Engineer/Researcher at <a href="http://deeplab.ai/">Deeplab</a> on Scene Graph Generation. Before Deeplab, I also worked at <a href="https://www.metis.tech/">METIS Cybetechnology</a> as an AI Engineer on Natural Language Processing systems.</p>

            <p> <a href="cv_gkanatsios.pdf"><img src="icons/cv.png" height="16"></a> / 
                <a href="https://www.linkedin.com/in/nikolaos-gkanatsios-031a1013a/" target="_blank" ><img src="icons/linkedin.png" height="16"></a> / 
                <a href="https://scholar.google.gr/citations?user=jk7GqOEAAAAJ&hl=en" target="_blank"><img src="icons/google_scholar.png" height="16"></a> /
                <a href="https://github.com/nickgkan/" target="_blank" ><img src="icons/github_alt.png" height="16"></a> 
            </p>
          </td>
          <td width="30%"><div class="instructorphoto"><img src="teasers/me.jpg" id="nikos"></div></td>
        </tr>
      </table>
    </table>
  </div>
  <br>

  <div class="container">
    <h2> Publications </h2>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/iclr23_mem.gif"><img src="teasers/iclr23_mem.gif" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://arxiv.org/abs/2304.14382"><heading>Analogy-Forming Transformers for Few-Shot 3D Parsing</heading></a><br>
          <strong>Nikolaos Gkanatsios*</strong>, <a href="https://scholar.google.com/citations?user=RgeKqSAAAAAJ"> Mayank Singh*</a>, <a href="https://scholar.google.com/citations?user=lgHhJQ8AAAAJ"> Zhaoyuan Fang</a>, <a href="https://scholar.google.com/citations?user=06rffEkAAAAJ"> Shubham Tulsiani</a>, <a href="https://scholar.google.com/citations?user=FWp7728AAAAJ"> Katerina Fragkiadaki</a><br>
          <em><a href="https://iclr.cc/Conferences/2023"> International Conference on Learning Representations</a>, ICLR</em>, 2023<br>
          
          <div class="paper" id="metis">
            <a href="https://arxiv.org/pdf/2304.14382.pdf">PDF</a> / 
            <a href="https://github.com/nickgkan/analogicalnets">GitHub</a> /
            <a href="https://analogicalnets.github.io/">Project Page</a>
          </div>
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/rss23_main.png"><img src="teasers/rss23_main.png" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://arxiv.org/abs/2304.14391"><heading>Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement</heading></a><br>
          <strong>Nikolaos Gkanatsios*</strong>, <a href="https://scholar.google.com/citations?&user=BUbOYGQAAAAJ"> Ayush Jain*</a>, <a href="https://scholar.google.com.sg/citations?user=Kbi2t9sAAAAJ"> Xian Zhou</a>, <a href="https://www.ri.cmu.edu/ri-people/yunchu-zhang/"> Yunchu Zhang</a>, <a href="https://scholar.google.ch/citations?user=NB4pgZYAAAAJ"> Chris Atkeson</a>, <a href="https://scholar.google.com/citations?user=FWp7728AAAAJ"> Katerina Fragkiadaki</a><br>
          <em><a href="https://roboticsconference.org/"> Robotics: Science and Systems</a>, RSS</em>, 2023<br>
          
          <div class="paper" id="metis">
            <a href="https://arxiv.org/pdf/2304.14391.pdf">PDF</a> / 
            <a href="https://github.com/ayushjain1144/ebmplanner">GitHub</a> /
            <a href="https://ebmplanner.github.io/">Project Page</a>
          </div>
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/bdetr.jpg"><img src="teasers/bdetr.jpg" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://arxiv.org/abs/2112.08879"><heading>Bottom Up Top Down Detection Transformers for Language Grounding in Images and Point Clouds</heading></a><br>
          <a href="https://scholar.google.com/citations?&user=BUbOYGQAAAAJ"> Ayush Jain*</a>, <strong>Nikolaos Gkanatsios*</strong>, <a href="https://scholar.google.com/citations?&user=hgaAO6QAAAAJ"> Ishita Mediratta</a>, <a href="https://scholar.google.com/citations?user=FWp7728AAAAJ"> Katerina Fragkiadaki</a><br>
          <em><a href="https://www.ortra.com/events/eccv/Home.aspx"> European Conference on Computer Vision</a>, ECCV</em>, 2022<br>
          
          <div class="paper" id="metis">
            <a href="https://arxiv.org/pdf/2112.08879.pdf">PDF</a> / 
            <a href="https://github.com/nickgkan/butd_detr">GitHub</a> /
            <a href="https://butd-detr.github.io/">Project Page</a>
          </div>
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/gcd.png"><img src="teasers/gcd.png" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Diomataris_Grounding_Consistency_Distilling_Spatial_Common_Sense_for_Precise_Visual_Relationship_ICCV_2021_paper.html"><heading>Grounding Consistency: Distilling Spatial Common Sense for Precise Visual Relationship Detection</heading></a><br>
          <a href="https://deeplab.ai/team-member/markosdiomataris/"> Markos Diomataris</a>, <strong>Nikolaos Gkanatsios</strong>, <a href="https://scholar.google.com/citations?user=_0Y1M6MAAAAJ"> Vassilis Pitsikalis</a>, <a href="https://scholar.google.com/citations?user=A2XydgGCY9gC"> Petros Maragos</a><br>
          <em><a href="https://iccv2021.thecvf.com/home"> International Conference on Computer Vision</a>, ICCV</em>, 2021<br>
          
          <div class="paper" id="metis">
            <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Diomataris_Grounding_Consistency_Distilling_Spatial_Common_Sense_for_Precise_Visual_Relationship_ICCV_2021_paper.pdf">PDF</a> / 
            <a href="https://github.com/deeplab-ai/grounding-consistent-vrd">GitHub</a>
          </div>
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/bmvc20_teaser.png"><img src="teasers/bmvc20_teaser.png" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://www.bmvc2020-conference.com/conference/papers/paper_0772.html"><heading>From Saturation to Zero-Shot Visual Relationship Detection Using Local Context
</heading></a><br>
          <strong>Nikolaos Gkanatsios</strong>, <a href="https://scholar.google.com/citations?user=_0Y1M6MAAAAJ"> Vassilis Pitsikalis</a>, <a href="https://scholar.google.com/citations?user=A2XydgGCY9gC"> Petros Maragos</a><br>
          <em><a href="https://www.bmvc2020-conference.com/"> British Machine Vision Conference</a>, BMVC</em>, 2020<br>
          
          <div class="paper" id="metis">
            <a href="https://www.bmvc2020-conference.com/assets/papers/0772.pdf">PDF</a> / 
            <a href="https://github.com/deeplab-ai/zs-vrd-bmvc20">GitHub</a>
          </div>
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/rss20_teaser.png"><img src="teasers/rss20_teaser.png" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://sites.google.com/view/rss20vlrrm"><heading>Revisiting Grasp Map Representation with a Focus on Orientation in Grasp Synthesis</heading></a><br>
          <strong>Nikolaos Gkanatsios</strong>, <a href="https://scholar.google.com/citations?user=mlho5FkAAAAJ"> Georgia Chalvarzaki</a>, <a href="https://scholar.google.com/citations?user=A2XydgGCY9gC"> Petros Maragos</a>, <a href="https://scholar.google.com/citations?user=-kIVAcAAAAAJ"> Jan Peters</a><br>
          <em><a href="https://sites.google.com/view/rss20vlrrm"> Visual Learning and Reasoning for Robotic Manipulation</a>, RSS Workshop</em>, 2020<br>
          
          <div class="paper" id="metis">
            <a href="https://rss2020vlrrm.github.io/papers/5_CameraReadySubmission_revisit_grasp_map_CRV.pdf">PDF</a>
          </div>
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/att_fig_atr.png"><img src="teasers/att_fig_atr.png" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://cs.stanford.edu/people/ranjaykrishna/sgrl/index.html#accepte"><heading>Attention-Translation-Relation Network for Scalable Scene Graph Generation</heading></a><br>
          <strong>Nikolaos Gkanatsios</strong>, <a href="https://scholar.google.com/citations?user=_0Y1M6MAAAAJ"> Vassilis Pitsikalis</a>, <a href="https://scholar.google.com/citations?user=lsWiNxIAAAAJ"> Petros Koutras</a>, <a href="https://scholar.google.com/citations?user=A2XydgGCY9gC"> Petros Maragos</a><br>
          <em><a href="https://cs.stanford.edu/people/ranjaykrishna/sgrl/index.html"> Scene Graph Representation and Learning</a>, ICCVW</em>, 2019<br>
          
          <div class="paper" id="metis">
            <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/SGRL/Gkanatsios_Attention-Translation-Relation_Network_for_Scalable_Scene_Graph_Generation_ICCVW_2019_paper.pdf">PDF</a> / 
            <a href="https://github.com/nickgkan/atr-net">GitHub</a>
          </div>
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/icip_demo.png"><img src="teasers/icip_demo.png" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://ieeexplore.ieee.org/abstract/document/8803015"><heading>Showcasing Deeply Supervised Multimodal Attentional Translation Embeddings: a Demo for Visual Relationship Detection</heading></a><br>
          <strong>Nikolaos Gkanatsios</strong>, <a href="https://scholar.google.com/citations?user=_0Y1M6MAAAAJ"> Vassilis Pitsikalis</a>, <a href="https://scholar.google.com/citations?user=lsWiNxIAAAAJ"> Petros Koutras</a>, <a href="https://scholar.google.com/citations?user=5ll6AGgAAAAJ"> Athanasia Zlatintsi</a>, <a href="https://scholar.google.com/citations?user=A2XydgGCY9gC"> Petros Maragos</a><br>
          <em>International Conference of Image Processing (ICIP)</em>, 2019<br>
          
          <div class="paper" id="metis">
            <a href="http://deeplab.ai/demo/vrd/">New Demo Webpage</a>
          </div>
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/ICIP Architecture.png"><img src="teasers/ICIP Architecture.png" alt="game" width="150" height="70" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://arxiv.org/abs/1902.05829"><heading>Deeply Supervised Multimodal Attentional Translation Embeddings for Visual Relationship Detection</heading></a><br>
          <strong>Nikolaos Gkanatsios</strong>, <a href="https://scholar.google.com/citations?user=_0Y1M6MAAAAJ"> Vassilis Pitsikalis</a>, <a href="https://scholar.google.com/citations?user=lsWiNxIAAAAJ"> Petros Koutras</a>, <a href="https://scholar.google.com/citations?user=5ll6AGgAAAAJ"> Athanasia Zlatintsi</a>, <a href="https://scholar.google.com/citations?user=A2XydgGCY9gC"> Petros Maragos</a><br>
          <em>International Conference of Image Processing (ICIP)</em>, 2019 <strong>(oral)</strong><br>
          
          <div class="paper" id="metis">
            <a href="https://arxiv.org/abs/1902.05829">Arxiv</a> / 
            <a href="https://github.com/nickgkan/ds-matranse">GitHub</a> / 
            <a href="http://deeplab.ai/project/visual-relationship-detection/">DeepLab project page</a>
          </div>
        </td> 
        </td>
      </table>
    </div>
    
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><a href="teasers/METIS_UI.gif"><img src="teasers/METIS_UI.gif" alt="game" width="150" height="120" style="border-style: none">
        <td width="75%" valign="top">
          <p><a href="https://link.springer.com/chapter/10.1007/978-3-319-99972-2_2"><heading>Metis: A Scalable Natural-Language-Based Intelligent Personal Assistant for Maritime Services</heading></a><br>
          <strong>Nikolaos Gkanatsios</strong>, <a href="https://www.semanticscholar.org/author/Konstantina-Mermikli/48685397"> Konstantina Mermikli</a>, <a href="https://www.semanticscholar.org/author/Serafeim-Katsikas/2687823"> Serafeim Katsikas</a><br>
          <em>International Conference of Information and Software Technologies (ICIST)</em>, 2018 <strong>(oral)</strong><br>
          
          <div class="paper" id="metis">
            <a href="https://docs.google.com/presentation/d/1ns3-r1IOmdvVxro7N8hIz8NSnsRq2inW49aCMNkz73o/edit?usp=sharing">Presentation Slides</a>     
          </div>
        </td> 
        </td>
      </table>
    </div>
    <hr>
  </div>
  <br>

  <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>News</h2>
      <div class="news">
        <ul>
         <li><span> Our <a href="https://www.amazon.science/alexa-prize/teams/symbiote-2022">team</a> got the second place in the <a href="https://eval.ai/web/challenges/challenge-page/1450/leaderboard/3644">Alexa Prize SimBot Public Benchmark Challenge</a>!</span></li>
         <li><span> <a href="http://deeplab.ai/demo/vrd/">VRD demo is live</a> again with a new, much updated design, test it yourself!</span></li>
         <li><span> As of Fall 2020, I am a PhD student at CMU!</span></li>
         <li><span> Congratulations to my friend and collaborator Petros Koutras on successfully defending his PhD dissertation! May our paths cross again!</span></li>
         <li><span> Our live demo about Deeply Supervised Multimodal Attentional Translation Embeddings at ICIP 2019 attracted a lot of attention! We are releasing it soon with a public IP.</span></li>
         <li><span> Awarded by the National Technical University of Athens for being the 1st in Systems and Electronics major among the class of 2017!</span></li>
         <li><span> Gave a talk at <a href="https://voxxeddays.com/athens/">Voxxed Days Athens</a> about METIS's <a href="https://www.metis.tech/nikos-gkanatsios-at-voxxeddays-athens-a-scalable-maritime-platform-providing-services-through-an-nlp-based-intelligent-personal-assistant/">Scalable Maritime Platform Providing Services Through an NLP-Based Intelligent Personal Assistant</a>.</span></li> 
        </ul>
      </div>
    </table>
  </div>
  <br>

  <div class="container">
    <h2> Other Projects </h2>
    <p>A (not exhaustive) list of some unpublished projects and less technical stuff is <a href="project_pages/index.html">here</a>.</p>
    <p style="text-align:right;">Template stolen from <a href="https://gkioxari.github.io/">Georgia Gkioxari</a></p>
  </div>
  <br>
          
</body>
</html>
